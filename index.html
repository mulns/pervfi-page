<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>Perception-Oriented Video Frame Interpolation via Asymmetric Blending</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static//favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Perception-Oriented Video Frame Interpolation via Asymmetric Blending</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              Guangyang Wu<sup>1</sup>,
            </span>
            <span class="author-block">
              Xin Tao<sup>2</sup>,
            </span>
            <span class="author-block">
              Changlin Li<sup>3</sup>,
            </span>
            <span class="author-block">
              Wenyi Wang<sup>4</sup>,
            </span>
            <span class="author-block">
              Xiaohong Liu<sup>1+</sup>,
            </span>
            <span class="author-block">
                Qingqing Zheng<sup>5+</sup>,
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>Shanghai Jiao Tong University,</span>
            <span class="author-block"><sup>2</sup>Kuaishou Technology,</span>
            <span class="author-block"><sup>3</sup>SeeKoo,</span>
          </div>
          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>4</sup>University of Electronic Science and Technology of China,</span>
          </div>
          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>5</sup>Shenzhen Institute of Advanced Technology, Chinese Academy of Sciences,</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://arxiv.org/pdf/2404.06692.pdf"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
             <!-- <span class="link-block">
                <a href="https://arxiv.org/abs/2011.12948"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span> -->
              <!-- Video Link. -->
              <!-- Code Link. -->
              <span class="link-block">
                <a 
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
              <!-- Dataset Link. -->
              <!-- <span class="link-block">
                <a href="https://github.com/google/nerfies/releases/tag/0.1"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="far fa-images"></i>
                  </span>
                  <span>Data</span>
                  </a> -->
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column">
          <div class="content">
            <video id="similar_work-video" autoplay controls muted loop playsinline height="100%">
              <source src="./static/videos/3.mp4"
                      type="video/mp4">
            </video>
          </div>
      </div>
    </div>
  </div>
</div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
           Previous methods for Video Frame Interpolation (VFI) have encountered challenges, notably the manifestation of blur and ghosting effects.
            These issues can be traced back to two pivotal factors: unavoidable motion errors and misalignment in supervision. 
            In practice, motion estimates often prove to be error-prone, resulting in misaligned features.
            Furthermore, the reconstruction loss tends to bring blurry results, particularly in misaligned regions. 
          </p>
          <p>
            To mitigate these challenges, we propose a new paradigm called PerVFI (Perception-oriented Video Frame Interpolation). 
            Our approach incorporates an Asymmetric Synergistic Blending module (ASB) that utilizes features from both sides to synergistically blend intermediate features. 
            One reference frame emphasizes primary content, while the other contributes complementary information. 
            To impose a stringent constraint on the blending process, we introduce a self-learned sparse quasi-binary mask which effectively mitigates ghosting and blur artifacts in the output. 
            Additionally, we employ a normalizing flow-based generator and utilize the negative log-likelihood loss to learn the conditional distribution of the output, which further facilitates the generation of clear and fine details. 
            Experimental results validate the superiority of PerVFI, demonstrating significant improvements in perceptual quality compared to existing methods.
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">  
    <!-- Paper video. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Demo Video on DAVIS</h2>
        <video id="similar_work-video" autoplay controls muted loop playsinline height="100%">
          <source src="./static/videos/exhibit_1.mp4"
                  type="video/mp4">
        </video>

        <video id="similar_work-video" autoplay controls muted loop playsinline height="100%">
          <source src="./static/videos/exhibit_2.mp4"
                  type="video/mp4">
        </video>

        <video id="similar_work-video" autoplay controls muted loop playsinline height="100%">
          <source src="./static/videos/exhibit_3.mp4"
                  type="video/mp4">
        </video>

        <div class="content has-text-justified">
          <p>
            The videos above show some of the results of our experiment. In the videos, the one on the left is the low frame rate video, 
            and the one on the right is the video after upsampling by our algorithm. It can be seen that our experiment has achieved very good results.
          </p>
        </div>
      </div>
    </div>
    <!--/ Paper video. -->
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">

      <!-- similar work. -->
      <div class="column">
          <div class="content">
            <h2 class="title is-3">Competitive Methods</h2>
            <video id="similar_work-video" autoplay controls muted loop playsinline height="100%">
              <source src="./static/videos/1.mp4"
                      type="video/mp4">
            </video>

            <video id="similar_work-video" autoplay controls muted loop playsinline height="100%">
              <source src="./static/videos/2.mp4"
                      type="video/mp4">
            </video>

            <div class="content has-text-justified">
              <p>
                When working on tasks related to video frame interpolation, we often encounter problems such as blurred portraits and scenes. 
                In the video above, the video on the top left is the Ground-truth, 
                the second and third videos are videos filled in by 
                <a href="https://github.com/MCG-NJU/EMA-VFI?tab=readme-ov-file">EMA-VFI models</a> and <a href="https://nk-cs-zzl.github.io/projects/amt/index.html">AMT models</a> respectively, 
                and the video on the bottom right is the result of our model. 
                From the video effect, we can find that our model's results are clearer than other models, and there are significant achievements in solving the problem of blurring.
            </div>
          </div>
        </div>
      <!--/ similar work. -->
    </div>
  </div>
</section>

<!-- Paper poster -->
<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column">
        <div class="content">
          <h2 class="title">Manuscript (Accepeted by CVPR 2024)</h2>

          <iframe  src="./static/pdf/2404.06692.pdf" width="100%" height="550">
              </iframe>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@article{park2021nerfies,
  title     ={Perception-Oriented Video Frame Interpolation via Asymmetric Blending},
  author    ={Wu, Guangyang and Tao, Xin and Li, Changlin and Wang, Wenyi and Liu, Xiaohong and Zheng, Qingqing},
  journal   ={arXiv preprint arXiv:2404.06692},
  year      ={2024},
}</code></pre>
  </div>
</section>


<footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            We borrow the website <a href="https://github.com/nerfies/nerfies.github.io">template</a> from this,
            many thanks for their great help!
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
